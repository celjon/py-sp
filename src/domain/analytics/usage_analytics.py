# src/domain/service/analytics/usage_analytics.py
"""
Production-ready Usage Analytics Service
–î–µ—Ç–∞–ª—å–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è API –¥–ª—è billing –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
"""

import time
import json
from datetime import datetime, timedelta, timezone
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, asdict
from enum import Enum

from ..entity.api_key import ApiKey
from ..entity.client_usage import ApiUsageRecord, ApiUsageStats, RequestStatus


class AnalyticsEvent(Enum):
    """–¢–∏–ø—ã –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Å–æ–±—ã—Ç–∏–π"""

    API_REQUEST = "api_request"
    SPAM_DETECTION = "spam_detection"
    RATE_LIMIT_HIT = "rate_limit_hit"
    ERROR_OCCURRED = "error_occurred"
    AUTHENTICATION_FAILED = "auth_failed"


@dataclass(frozen=True)
class UsageMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥–ª—è –ø–µ—Ä–∏–æ–¥–∞"""

    api_key_id: int
    period: str  # "hour", "day", "week", "month"
    timestamp: datetime

    # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0

    # Spam detection –º–µ—Ç—Ä–∏–∫–∏
    spam_detected: int = 0
    clean_detected: int = 0
    avg_confidence: float = 0.0

    # –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
    avg_response_time_ms: float = 0.0
    p95_response_time_ms: float = 0.0
    max_response_time_ms: float = 0.0

    # –û–±—ä–µ–º –¥–∞–Ω–Ω—ã—Ö
    total_bytes_processed: int = 0

    # Rate limiting
    rate_limit_hits: int = 0

    # –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã
    top_endpoints: Dict[str, int] = None

    def __post_init__(self):
        if self.top_endpoints is None:
            object.__setattr__(self, "top_endpoints", {})

    @property
    def success_rate(self) -> float:
        """–ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
        if self.total_requests == 0:
            return 0.0
        return (self.successful_requests / self.total_requests) * 100

    @property
    def error_rate(self) -> float:
        """–ü—Ä–æ—Ü–µ–Ω—Ç –æ—à–∏–±–æ–∫"""
        if self.total_requests == 0:
            return 0.0
        return (self.failed_requests / self.total_requests) * 100

    @property
    def spam_detection_rate(self) -> float:
        """–ü—Ä–æ—Ü–µ–Ω—Ç –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Å–ø–∞–º–∞"""
        total_detections = self.spam_detected + self.clean_detected
        if total_detections == 0:
            return 0.0
        return (self.spam_detected / total_detections) * 100

    def to_dict(self) -> Dict[str, Any]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è JSON"""
        data = asdict(self)
        data["timestamp"] = self.timestamp.isoformat()
        data["success_rate"] = round(self.success_rate, 2)
        data["error_rate"] = round(self.error_rate, 2)
        data["spam_detection_rate"] = round(self.spam_detection_rate, 2)
        return data


@dataclass
class AlertRule:
    """–ü—Ä–∞–≤–∏–ª–æ –¥–ª—è –∞–ª–µ—Ä—Ç–æ–≤"""

    name: str
    condition: str  # "error_rate > 10", "response_time > 2000", etc.
    threshold: float
    metric: str
    period_minutes: int = 5
    enabled: bool = True

    def check_violation(self, metrics: UsageMetrics) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞—Ä—É—à–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª–∞"""
        try:
            metric_value = getattr(metrics, self.metric, 0)

            if self.condition.startswith(">"):
                return metric_value > self.threshold
            elif self.condition.startswith("<"):
                return metric_value < self.threshold
            elif self.condition.startswith(">="):
                return metric_value >= self.threshold
            elif self.condition.startswith("<="):
                return metric_value <= self.threshold

            return False
        except Exception:
            return False


class UsageAnalytics:
    """
    Production-ready Usage Analytics Service

    Features:
    - Real-time –º–µ—Ç—Ä–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è API
    - –î–µ—Ç–∞–ª—å–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø–æ –∫–ª–∏–µ–Ω—Ç–∞–º
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∞–ª–µ—Ä—Ç—ã
    - Billing –º–µ—Ç—Ä–∏–∫–∏
    - Performance –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
    - Fraud detection –±–∞–∑–æ–≤—ã–π
    """

    def __init__(
        self, usage_repo, redis_client=None, enable_real_time: bool = True  # UsageRepository
    ):
        self.usage_repo = usage_repo
        self.redis = redis_client
        self.enable_real_time = enable_real_time

        # Real-time –º–µ—Ç—Ä–∏–∫–∏ –∫—ç—à (–≤ production –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Redis)
        self._metrics_cache: Dict[str, UsageMetrics] = {}
        self._cache_ttl = 300  # 5 –º–∏–Ω—É—Ç

        # –ê–ª–µ—Ä—Ç—ã
        self._alert_rules: List[AlertRule] = []
        self._setup_default_alert_rules()

        # –°—á–µ—Ç—á–∏–∫–∏ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        self._processed_events = 0
        self._last_cleanup = time.time()

        print(f"üìä Usage Analytics –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (real-time: {enable_real_time})")

    async def track_api_request(
        self,
        api_key: ApiKey,
        endpoint: str,
        method: str,
        status: RequestStatus,
        processing_time_ms: float,
        request_size_bytes: int = 0,
        response_size_bytes: int = 0,
        client_ip: str = None,
        user_agent: str = None,
        is_spam_detected: bool = None,
        detection_confidence: float = None,
        detection_reason: str = None,
    ) -> None:
        """
        –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç API –∑–∞–ø—Ä–æ—Å –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏

        Args:
            api_key: API –∫–ª—é—á –∫–ª–∏–µ–Ω—Ç–∞
            endpoint: –í—ã–∑–≤–∞–Ω–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç
            method: HTTP –º–µ—Ç–æ–¥
            status: –°—Ç–∞—Ç—É—Å –∑–∞–ø—Ä–æ—Å–∞
            processing_time_ms: –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
            request_size_bytes: –†–∞–∑–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞
            response_size_bytes: –†–∞–∑–º–µ—Ä –æ—Ç–≤–µ—Ç–∞
            client_ip: IP –∞–¥—Ä–µ—Å –∫–ª–∏–µ–Ω—Ç–∞
            user_agent: User-Agent
            is_spam_detected: –ë—ã–ª –ª–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω —Å–ø–∞–º
            detection_confidence: –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–µ—Ç–µ–∫—Ü–∏–∏
            detection_reason: –ü—Ä–∏—á–∏–Ω–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏
        """
        try:
            # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            usage_record = ApiUsageRecord(
                api_key_id=api_key.id,
                endpoint=endpoint,
                method=method,
                status=status,
                client_ip=client_ip or "unknown",
                user_agent=user_agent or "unknown",
                request_size_bytes=request_size_bytes,
                response_size_bytes=response_size_bytes,
                processing_time_ms=processing_time_ms,
                is_spam_detected=is_spam_detected,
                detection_confidence=detection_confidence,
                detection_reason=detection_reason,
                timestamp=datetime.now(timezone.utc),
            )

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
            await self.usage_repo.record_api_usage(usage_record)

            # –û–±–Ω–æ–≤–ª—è–µ–º real-time –º–µ—Ç—Ä–∏–∫–∏
            if self.enable_real_time:
                await self._update_real_time_metrics(usage_record)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–ª–µ—Ä—Ç—ã
            await self._check_alert_rules(api_key.id, usage_record)

            self._processed_events += 1

        except Exception as e:
            print(f"Error tracking API request: {e}")
            # –ù–µ –±–ª–æ–∫–∏—Ä—É–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Ç–æ–∫ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö –∞–Ω–∞–ª–∏—Ç–∏–∫–∏

    async def get_usage_metrics(
        self, api_key_id: int, period: str = "hour", hours_back: int = 24
    ) -> List[UsageMetrics]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∑–∞ –ø–µ—Ä–∏–æ–¥

        Args:
            api_key_id: ID API –∫–ª—é—á–∞
            period: –ü–µ—Ä–∏–æ–¥ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ ("hour", "day", "week")
            hours_back: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å–æ–≤ –Ω–∞–∑–∞–¥

        Returns:
            –°–ø–∏—Å–æ–∫ –º–µ—Ç—Ä–∏–∫ –ø–æ –ø–µ—Ä–∏–æ–¥–∞–º
        """
        try:
            end_time = datetime.now(timezone.utc)
            start_time = end_time - timedelta(hours=hours_back)

            # –ü–æ–ª—É—á–∞–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –ë–î
            raw_metrics = await self.usage_repo.get_aggregated_usage(
                api_key_id=api_key_id, start_time=start_time, end_time=end_time, period=period
            )

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ UsageMetrics
            metrics = []
            for raw_metric in raw_metrics:
                metric = UsageMetrics(
                    api_key_id=api_key_id,
                    period=period,
                    timestamp=raw_metric["period_start"],
                    total_requests=raw_metric["total_requests"],
                    successful_requests=raw_metric["successful_requests"],
                    failed_requests=raw_metric["failed_requests"],
                    spam_detected=raw_metric["spam_detected"],
                    clean_detected=raw_metric["clean_detected"],
                    avg_confidence=raw_metric["avg_confidence"],
                    avg_response_time_ms=raw_metric["avg_response_time_ms"],
                    p95_response_time_ms=raw_metric.get("p95_response_time_ms", 0),
                    max_response_time_ms=raw_metric["max_response_time_ms"],
                    total_bytes_processed=raw_metric["total_bytes_processed"],
                    rate_limit_hits=raw_metric.get("rate_limit_hits", 0),
                    top_endpoints=raw_metric.get("top_endpoints", {}),
                )
                metrics.append(metric)

            return metrics

        except Exception as e:
            print(f"Error getting usage metrics: {e}")
            return []

    async def get_real_time_metrics(self, api_key_id: int, last_minutes: int = 5) -> UsageMetrics:
        """
        –ü–æ–ª—É—á–∞–µ—Ç real-time –º–µ—Ç—Ä–∏–∫–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –º–∏–Ω—É—Ç

        Args:
            api_key_id: ID API –∫–ª—é—á–∞
            last_minutes: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–∏–Ω—É—Ç

        Returns:
            –¢–µ–∫—É—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
        """
        try:
            cache_key = f"realtime_metrics:{api_key_id}:{last_minutes}"

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
            cached_metric = self._metrics_cache.get(cache_key)
            if cached_metric and self._is_cache_valid(cached_metric.timestamp):
                return cached_metric

            # –ü–æ–ª—É—á–∞–µ–º –∏–∑ –ë–î
            end_time = datetime.now(timezone.utc)
            start_time = end_time - timedelta(minutes=last_minutes)

            raw_data = await self.usage_repo.get_usage_stats(
                api_key_id=api_key_id,
                period=None,  # Real-time
                start_time=start_time,
                end_time=end_time,
            )

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –º–µ—Ç—Ä–∏–∫–∏
            metric = UsageMetrics(
                api_key_id=api_key_id,
                period="realtime",
                timestamp=end_time,
                total_requests=raw_data.total_requests,
                successful_requests=raw_data.successful_requests,
                failed_requests=raw_data.error_requests,
                spam_detected=raw_data.spam_detected,
                clean_detected=raw_data.clean_detected,
                avg_confidence=raw_data.avg_confidence,
                avg_response_time_ms=raw_data.avg_processing_time_ms,
                max_response_time_ms=raw_data.max_processing_time_ms,
                total_bytes_processed=int(raw_data.total_data_processed_bytes),
            )

            # –ö—ç—à–∏—Ä—É–µ–º
            self._metrics_cache[cache_key] = metric

            return metric

        except Exception as e:
            print(f"Error getting real-time metrics: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—É—é –º–µ—Ç—Ä–∏–∫—É
            return UsageMetrics(
                api_key_id=api_key_id, period="realtime", timestamp=datetime.now(timezone.utc)
            )

    async def get_billing_metrics(
        self, api_key_id: int, start_date: datetime, end_date: datetime
    ) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –±–∏–ª–ª–∏–Ω–≥–∞

        Args:
            api_key_id: ID API –∫–ª—é—á–∞
            start_date: –ù–∞—á–∞–ª–æ –ø–µ—Ä–∏–æ–¥–∞
            end_date: –ö–æ–Ω–µ—Ü –ø–µ—Ä–∏–æ–¥–∞

        Returns:
            Billing –º–µ—Ç—Ä–∏–∫–∏
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            usage_stats = await self.usage_repo.get_usage_stats(
                api_key_id=api_key_id, period=None, start_time=start_date, end_time=end_date
            )

            # –ü–æ–ª—É—á–∞–µ–º breakdown –ø–æ –¥–Ω—è–º
            daily_metrics = await self.get_usage_metrics(
                api_key_id=api_key_id,
                period="day",
                hours_back=int((end_date - start_date).total_seconds() / 3600),
            )

            # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã
            top_endpoints = await self.usage_repo.get_top_endpoints(
                api_key_id=api_key_id, hours=int((end_date - start_date).total_seconds() / 3600)
            )

            # –í—ã—á–∏—Å–ª—è–µ–º billing –º–µ—Ç—Ä–∏–∫–∏
            billing_data = {
                "api_key_id": api_key_id,
                "billing_period": {
                    "start": start_date.isoformat(),
                    "end": end_date.isoformat(),
                    "days": (end_date - start_date).days,
                },
                "usage_summary": {
                    "total_requests": usage_stats.total_requests,
                    "successful_requests": usage_stats.successful_requests,
                    "error_requests": usage_stats.error_requests,
                    "success_rate": round(usage_stats.success_rate, 2),
                    "total_data_processed_mb": round(
                        usage_stats.total_data_processed_bytes / 1024 / 1024, 2
                    ),
                },
                "spam_detection": {
                    "spam_detected": usage_stats.spam_detected,
                    "clean_detected": usage_stats.clean_detected,
                    "detection_rate": round(usage_stats.spam_detection_rate, 2),
                    "avg_confidence": round(usage_stats.avg_confidence, 3),
                },
                "performance": {
                    "avg_response_time_ms": round(usage_stats.avg_processing_time_ms, 2),
                    "max_response_time_ms": round(usage_stats.max_processing_time_ms, 2),
                },
                "daily_breakdown": [metric.to_dict() for metric in daily_metrics],
                "top_endpoints": top_endpoints[:10],  # –¢–æ–ø 10
                "generated_at": datetime.now(timezone.utc).isoformat(),
            }

            return billing_data

        except Exception as e:
            print(f"Error getting billing metrics: {e}")
            return {"error": "Failed to generate billing metrics", "api_key_id": api_key_id}

    async def detect_anomalies(self, api_key_id: int, hours_back: int = 24) -> List[Dict[str, Any]]:
        """
        –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç –∞–Ω–æ–º–∞–ª–∏–∏ –≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ API

        Args:
            api_key_id: ID API –∫–ª—é—á–∞
            hours_back: –ü–µ—Ä–∏–æ–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –°–ø–∏—Å–æ–∫ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –∞–Ω–æ–º–∞–ª–∏–π
        """
        try:
            anomalies = []

            # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥
            metrics = await self.get_usage_metrics(
                api_key_id=api_key_id, period="hour", hours_back=hours_back
            )

            if len(metrics) < 3:  # –ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 3 —Ç–æ—á–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                return anomalies

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç—Ä–∞—Ñ–∏–∫
            request_counts = [m.total_requests for m in metrics[-24:]]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞
            avg_requests = sum(request_counts) / len(request_counts)

            # –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ–º —Å–ø–∞–π–∫–∏ —Ç—Ä–∞—Ñ–∏–∫–∞
            for metric in metrics[-6:]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 6 —á–∞—Å–æ–≤
                if metric.total_requests > avg_requests * 3:  # 3x –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ
                    anomalies.append(
                        {
                            "type": "traffic_spike",
                            "severity": "high",
                            "timestamp": metric.timestamp.isoformat(),
                            "description": f"Traffic spike: {metric.total_requests} requests (avg: {avg_requests:.0f})",
                            "metric": "total_requests",
                            "value": metric.total_requests,
                            "threshold": avg_requests * 3,
                        }
                    )

            # –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ–º –≤—ã—Å–æ–∫–∏–π error rate
            for metric in metrics[-6:]:
                if metric.error_rate > 20:  # –ë–æ–ª—å—à–µ 20% –æ—à–∏–±–æ–∫
                    anomalies.append(
                        {
                            "type": "high_error_rate",
                            "severity": "high",
                            "timestamp": metric.timestamp.isoformat(),
                            "description": f"High error rate: {metric.error_rate:.1f}%",
                            "metric": "error_rate",
                            "value": metric.error_rate,
                            "threshold": 20,
                        }
                    )

            # –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ–º –º–µ–¥–ª–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
            response_times = [m.avg_response_time_ms for m in metrics if m.avg_response_time_ms > 0]
            if response_times:
                avg_response_time = sum(response_times) / len(response_times)

                for metric in metrics[-6:]:
                    if metric.avg_response_time_ms > avg_response_time * 2:  # 2x –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ
                        anomalies.append(
                            {
                                "type": "slow_responses",
                                "severity": "medium",
                                "timestamp": metric.timestamp.isoformat(),
                                "description": f"Slow responses: {metric.avg_response_time_ms:.0f}ms (avg: {avg_response_time:.0f}ms)",
                                "metric": "avg_response_time_ms",
                                "value": metric.avg_response_time_ms,
                                "threshold": avg_response_time * 2,
                            }
                        )

            return anomalies

        except Exception as e:
            print(f"Error detecting anomalies: {e}")
            return []

    async def get_global_statistics(self, hours_back: int = 24) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –≤—Å–µ–º API –∫–ª—é—á–∞–º

        Args:
            hours_back: –ü–µ—Ä–∏–æ–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –ì–ª–æ–±–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        """
        try:
            global_stats = await self.usage_repo.get_global_usage_stats(hours_back)

            # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∞–Ω–∞–ª–∏—Ç–∏–∫—É
            end_time = datetime.now(timezone.utc)
            start_time = end_time - timedelta(hours=hours_back)

            return {
                "period": {
                    "start": start_time.isoformat(),
                    "end": end_time.isoformat(),
                    "hours": hours_back,
                },
                "global_metrics": global_stats,
                "system_health": {
                    "processed_events": self._processed_events,
                    "cache_size": len(self._metrics_cache),
                    "real_time_enabled": self.enable_real_time,
                    "alert_rules_count": len(self._alert_rules),
                },
                "generated_at": datetime.now(timezone.utc).isoformat(),
            }

        except Exception as e:
            print(f"Error getting global statistics: {e}")
            return {"error": "Failed to get global statistics"}

    async def _update_real_time_metrics(self, usage_record: ApiUsageRecord) -> None:
        """–û–±–Ω–æ–≤–ª—è–µ—Ç real-time –º–µ—Ç—Ä–∏–∫–∏"""
        try:
            if not self.redis:
                return

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫–∏ –≤ Redis –¥–ª—è real-time –¥–∞—à–±–æ—Ä–¥–∞
            timestamp = int(usage_record.timestamp.timestamp())
            minute_key = f"realtime:{usage_record.api_key_id}:{timestamp // 60}"

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º Redis pipeline –¥–ª—è –∞—Ç–æ–º–∞—Ä–Ω–æ—Å—Ç–∏
            async with self.redis.pipeline() as pipe:
                await pipe.hincrby(minute_key, "total_requests", 1)

                if usage_record.status == RequestStatus.SUCCESS:
                    await pipe.hincrby(minute_key, "successful_requests", 1)
                else:
                    await pipe.hincrby(minute_key, "failed_requests", 1)

                if usage_record.is_spam_detected is not None:
                    if usage_record.is_spam_detected:
                        await pipe.hincrby(minute_key, "spam_detected", 1)
                    else:
                        await pipe.hincrby(minute_key, "clean_detected", 1)

                await pipe.expire(minute_key, 3600)  # TTL 1 —á–∞—Å
                await pipe.execute()

        except Exception as e:
            print(f"Error updating real-time metrics: {e}")

    async def _check_alert_rules(self, api_key_id: int, usage_record: ApiUsageRecord) -> None:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–∞–≤–∏–ª–∞ –∞–ª–µ—Ä—Ç–æ–≤"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
            current_metrics = await self.get_real_time_metrics(api_key_id, 5)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥–æ–µ –ø—Ä–∞–≤–∏–ª–æ
            for rule in self._alert_rules:
                if not rule.enabled:
                    continue

                if rule.check_violation(current_metrics):
                    await self._trigger_alert(rule, api_key_id, current_metrics)

        except Exception as e:
            print(f"Error checking alert rules: {e}")

    async def _trigger_alert(self, rule: AlertRule, api_key_id: int, metrics: UsageMetrics) -> None:
        """–ê–∫—Ç–∏–≤–∏—Ä—É–µ—Ç –∞–ª–µ—Ä—Ç"""
        try:
            alert_data = {
                "rule_name": rule.name,
                "api_key_id": api_key_id,
                "metric": rule.metric,
                "threshold": rule.threshold,
                "current_value": getattr(metrics, rule.metric, 0),
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "severity": "high" if rule.metric in ["error_rate", "response_time"] else "medium",
            }

            # –í production –∑–¥–µ—Å—å –æ—Ç–ø—Ä–∞–≤–∫–∞ –≤ Slack, email, PagerDuty –∏ —Ç.–¥.
            print(f"üö® ALERT: {rule.name} - API Key {api_key_id}")
            print(f"   {rule.metric}: {alert_data['current_value']} > {rule.threshold}")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–ª–µ—Ä—Ç –≤ –ë–î –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏
            if self.redis:
                alert_key = f"alerts:{api_key_id}:{int(time.time())}"
                await self.redis.setex(alert_key, 86400, json.dumps(alert_data))

        except Exception as e:
            print(f"Error triggering alert: {e}")

    def _setup_default_alert_rules(self) -> None:
        """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –∞–ª–µ—Ä—Ç–æ–≤"""
        self._alert_rules = [
            AlertRule(
                name="High Error Rate",
                condition="error_rate > 20",
                threshold=20,
                metric="error_rate",
                period_minutes=5,
            ),
            AlertRule(
                name="Slow Response Time",
                condition="avg_response_time_ms > 2000",
                threshold=2000,
                metric="avg_response_time_ms",
                period_minutes=5,
            ),
            AlertRule(
                name="Traffic Spike",
                condition="total_requests > 1000",
                threshold=1000,
                metric="total_requests",
                period_minutes=5,
            ),
        ]

    def _is_cache_valid(self, timestamp: datetime) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –∫—ç—à–∞"""
        return (datetime.now(timezone.utc) - timestamp).total_seconds() < self._cache_ttl

    def health_check(self) -> Dict[str, Any]:
        """Health check –¥–ª—è analytics —Å–µ—Ä–≤–∏—Å–∞"""
        try:
            return {
                "status": "healthy",
                "processed_events": self._processed_events,
                "cache_size": len(self._metrics_cache),
                "alert_rules": len(self._alert_rules),
                "real_time_enabled": self.enable_real_time,
                "last_cleanup": self._last_cleanup,
            }
        except Exception as e:
            return {"status": "error", "error": str(e)}


# Factory function
def create_usage_analytics(
    usage_repo, redis_client=None, config: Dict[str, Any] = None
) -> UsageAnalytics:
    """
    –§–∞–±—Ä–∏–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è Usage Analytics

    Args:
        usage_repo: Repository –¥–ª—è usage –¥–∞–Ω–Ω—ã—Ö
        redis_client: Redis –∫–ª–∏–µ–Ω—Ç
        config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

    Returns:
        –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π UsageAnalytics
    """
    if config is None:
        config = {}

    enable_real_time = config.get("enable_real_time", True)

    return UsageAnalytics(
        usage_repo=usage_repo, redis_client=redis_client, enable_real_time=enable_real_time
    )
