# src/domain/service/detector/openai.py
"""
Production-Ready OpenAI Spam Detector
–ö–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–ø–∞–º–∞ —Å –ø–æ–º–æ—â—å—é LLM
"""

import time
import logging
import json
from typing import Dict, Any, Optional, List

from ...entity.message import Message
from ...entity.detection_result import DetectorResult

logger = logging.getLogger(__name__)


class OpenAIDetector:
    """
    Production-ready –¥–µ—Ç–µ–∫—Ç–æ—Ä —Å–ø–∞–º–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ OpenAI LLM
    
    Features:
    - Context-aware –∞–Ω–∞–ª–∏–∑ —Å —É—á–µ—Ç–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    - –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ø–∞–º–∞ —á–µ—Ä–µ–∑ LLM
    - Comprehensive error handling
    - Performance monitoring
    - Fallback —Ä–µ–∂–∏–º—ã
    """
    
    def __init__(self, openai_gateway, config: Dict[str, Any] = None):
        """
        Args:
            openai_gateway: –®–ª—é–∑ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å OpenAI API
            config: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        """
        self.openai_gateway = openai_gateway
        self.config = config or {}
        
        # Detection settings
        self.min_text_length = self.config.get("min_text_length", 10)
        self.max_text_length = self.config.get("max_text_length", 4000)
        self.confidence_threshold = self.config.get("confidence_threshold", 0.7)
        
        # Performance settings
        self.timeout = self.config.get("timeout", 5.0)
        self.max_retries = self.config.get("max_retries", 2)
        self.retry_delay = self.config.get("retry_delay", 1.0)
        
        # Context settings
        self.use_user_context = self.config.get("use_user_context", True)
        self.analyze_patterns = self.config.get("analyze_patterns", True)
        
        # Metrics
        self._total_requests = 0
        self._successful_requests = 0
        self._failed_requests = 0
        self._spam_detected = 0
        self._total_processing_time = 0.0
        
        logger.info("üß† OpenAI Detector –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        logger.info(f"   Min length: {self.min_text_length}, Max length: {self.max_text_length}")
        logger.info(f"   Timeout: {self.timeout}s, Retries: {self.max_retries}")
    
    async def detect(self, message: Message, user_context: Dict[str, Any] = None) -> DetectorResult:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é OpenAI LLM
        
        Args:
            message: –°–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            user_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            
        Returns:
            DetectorResult —Å –∞–Ω–∞–ª–∏–∑–æ–º LLM
        """
        start_time = time.time()
        self._total_requests += 1
        
        text = message.text or ""
        
        logger.debug(f"üß† OpenAI –∞–Ω–∞–ª–∏–∑: '{text[:50]}{'...' if len(text) > 50 else ''}'")
        
        try:
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if len(text.strip()) < self.min_text_length:
                logger.debug(f"‚ö†Ô∏è –¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –¥–ª—è OpenAI: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
                return DetectorResult(
                    detector_name="OpenAI",
                    is_spam=False,
                    confidence=0.0,
                    details=f"Text too short for analysis ({len(text)} chars)",
                    processing_time_ms=(time.time() - start_time) * 1000
                )
            
            if len(text) > self.max_text_length:
                # –û–±—Ä–µ–∑–∞–µ–º —Ç–µ–∫—Å—Ç
                text = text[:self.max_text_length]
                logger.warning(f"‚ö†Ô∏è –¢–µ–∫—Å—Ç –æ–±—Ä–µ–∑–∞–Ω –¥–æ {self.max_text_length} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            analysis_context = self._prepare_analysis_context(message, user_context)
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ —Å retry logic
            openai_result = await self._analyze_with_retry(text, analysis_context)
            
            processing_time_ms = (time.time() - start_time) * 1000
            self._total_processing_time += processing_time_ms
            
            # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            is_spam, confidence, reasoning = self._parse_openai_result(openai_result)
            
            if is_spam:
                self._spam_detected += 1
                logger.warning(f"üö® OpenAI: –°–ü–ê–ú –æ–±–Ω–∞—Ä—É–∂–µ–Ω (confidence: {confidence:.3f}, –≤—Ä–µ–º—è: {processing_time_ms:.1f}ms)")
                logger.warning(f"   –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ: {reasoning}")
            else:
                logger.debug(f"‚úÖ OpenAI: —Å–æ–æ–±—â–µ–Ω–∏–µ —á–∏—Å—Ç–æ–µ (confidence: {confidence:.3f}, –≤—Ä–µ–º—è: {processing_time_ms:.1f}ms)")
            
            self._successful_requests += 1
            
            return DetectorResult(
                detector_name="OpenAI",
                is_spam=is_spam,
                confidence=confidence,
                details=reasoning,
                processing_time_ms=processing_time_ms
            )
            
        except Exception as e:
            self._failed_requests += 1
            processing_time_ms = (time.time() - start_time) * 1000
            
            logger.error(f"‚ö†Ô∏è OpenAI detector failed: {e}")
            
            # Graceful degradation
            return DetectorResult(
                detector_name="OpenAI",
                is_spam=False,
                confidence=0.0,
                details=f"OpenAI analysis failed: {str(e)}",
                error=str(e),
                processing_time_ms=processing_time_ms
            )
    
    def _prepare_analysis_context(self, message: Message, user_context: Dict[str, Any] = None) -> Dict[str, Any]:
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è OpenAI –∞–Ω–∞–ª–∏–∑–∞"""
        context = {
            "message_length": len(message.text or ""),
            "has_links": self._contains_links(message.text or ""),
            "has_mentions": self._contains_mentions(message.text or ""),
            "language": self._detect_primary_language(message.text or "")
        }
        
        if user_context and self.use_user_context:
            context.update({
                "is_new_user": user_context.get("is_new_user", False),
                "user_id": user_context.get("user_id"),
                "previous_warnings": user_context.get("previous_warnings", 0),
                "is_admin": user_context.get("is_admin_or_owner", False)
            })
        
        return context
    
    async def _analyze_with_retry(self, text: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∞–Ω–∞–ª–∏–∑ —Å retry logic"""
        last_error = None
        
        for attempt in range(self.max_retries + 1):
            try:
                if attempt > 0:
                    await asyncio.sleep(self.retry_delay * attempt)
                    logger.info(f"üîÑ OpenAI retry attempt {attempt + 1}")
                
                # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ OpenAI
                result = await asyncio.wait_for(
                    self.openai_gateway.analyze_spam(text, context),
                    timeout=self.timeout
                )
                
                return result
                
            except asyncio.TimeoutError as e:
                last_error = f"Timeout after {self.timeout}s"
                logger.warning(f"‚è∞ OpenAI timeout –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}")
                continue
            except Exception as e:
                last_error = str(e)
                logger.warning(f"‚ö†Ô∏è OpenAI –æ—à–∏–±–∫–∞ –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}: {e}")
                continue
        
        # –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –Ω–µ—É–¥–∞—á–Ω—ã
        raise RuntimeError(f"OpenAI analysis failed after {self.max_retries + 1} attempts: {last_error}")
    
    def _parse_openai_result(self, openai_result: Dict[str, Any]) -> tuple[bool, float, str]:
        """
        –ü–∞—Ä—Å–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç OpenAI –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç is_spam, confidence, reasoning
        
        Returns:
            (is_spam, confidence, reasoning)
        """
        try:
            is_spam = openai_result.get("is_spam", False)
            confidence = float(openai_result.get("confidence", 0.0))
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º confidence
            confidence = max(0.0, min(1.0, confidence))
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ
            reasoning = openai_result.get("reasoning", "No reasoning provided")
            if isinstance(reasoning, list):
                reasoning = "; ".join(reasoning)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            spam_indicators = openai_result.get("spam_indicators", [])
            if spam_indicators and isinstance(spam_indicators, list):
                reasoning += f" (–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã: {', '.join(spam_indicators)})"
            
            return is_spam, confidence, reasoning
            
        except (ValueError, TypeError) as e:
            logger.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ OpenAI —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {e}")
            logger.error(f"   Raw result: {openai_result}")
            
            # Fallback parsing
            return False, 0.0, "Failed to parse OpenAI result"
    
    def _contains_links(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ —Å—Å—ã–ª–æ–∫ –≤ —Ç–µ–∫—Å—Ç–µ"""
        import re
        link_patterns = [
            r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',
            r'www\.(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',
            r't\.me/[a-zA-Z0-9_]+',
            r'@[a-zA-Z0-9_]+',
        ]
        
        for pattern in link_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                return True
        
        return False
    
    def _contains_mentions(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –≤ —Ç–µ–∫—Å—Ç–µ"""
        import re
        return bool(re.search(r'@[a-zA-Z0-9_]+', text))
    
    def _detect_primary_language(self, text: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π —è–∑—ã–∫ —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return "unknown"
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–∏–º–≤–æ–ª—ã
        cyrillic_chars = sum(1 for c in text if '\u0400' <= c <= '\u04FF')
        latin_chars = sum(1 for c in text if c.isalpha() and not ('\u0400' <= c <= '\u04FF'))
        
        total_letters = cyrillic_chars + latin_chars
        if total_letters == 0:
            return "unknown"
        
        cyrillic_ratio = cyrillic_chars / total_letters
        
        if cyrillic_ratio >= 0.3:
            return "ru"
        elif cyrillic_ratio < 0.1:
            return "en"
        else:
            return "mixed"
    
    async def batch_detect(self, messages: List[Message], user_contexts: List[Dict[str, Any]] = None) -> List[DetectorResult]:
        """
        Batch –∞–Ω–∞–ª–∏–∑ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        
        Args:
            messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
            user_contexts: –°–ø–∏—Å–æ–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
            
        Returns:
            –°–ø–∏—Å–æ–∫ DetectorResult
        """
        if not messages:
            return []
        
        logger.info(f"üß† OpenAI batch –∞–Ω–∞–ª–∏–∑: {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π")
        
        results = []
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —è–∑—ã–∫–∞–º –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–º–ø—Ç–æ–≤
        grouped_messages = self._group_messages_by_language(messages)
        
        for language, msg_group in grouped_messages.items():
            try:
                # Batch –∞–Ω–∞–ª–∏–∑ –¥–ª—è –æ–¥–Ω–æ–≥–æ —è–∑—ã–∫–∞
                if hasattr(self.openai_gateway, 'analyze_spam_batch'):
                    batch_results = await self.openai_gateway.analyze_spam_batch(
                        [msg.text for msg in msg_group],
                        language=language
                    )
                    
                    for i, msg in enumerate(msg_group):
                        if i < len(batch_results):
                            is_spam, confidence, reasoning = self._parse_openai_result(batch_results[i])
                            results.append(DetectorResult(
                                detector_name="OpenAI",
                                is_spam=is_spam,
                                confidence=confidence,
                                details=reasoning
                            ))
                        else:
                            # Fallback –µ—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –º–µ–Ω—å—à–µ
                            results.append(DetectorResult(
                                detector_name="OpenAI",
                                is_spam=False,
                                confidence=0.0,
                                details="Batch result missing"
                            ))
                else:
                    # Fallback: –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
                    for msg in msg_group:
                        user_ctx = user_contexts[messages.index(msg)] if user_contexts else None
                        result = await self.detect(msg, user_ctx)
                        results.append(result)
                        
            except Exception as e:
                logger.error(f"‚ö†Ô∏è OpenAI batch –æ—à–∏–±–∫–∞ –¥–ª—è —è–∑—ã–∫–∞ {language}: {e}")
                
                # Fallback: –ø–æ–º–µ—á–∞–µ–º –∫–∞–∫ –æ—à–∏–±–∫—É
                for msg in msg_group:
                    results.append(DetectorResult(
                        detector_name="OpenAI",
                        is_spam=False,
                        confidence=0.0,
                        details=f"Batch analysis failed: {str(e)}",
                        error=str(e)
                    ))
        
        logger.info(f"‚úÖ OpenAI batch –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        return results
    
    def _group_messages_by_language(self, messages: List[Message]) -> Dict[str, List[Message]]:
        """–ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ —è–∑—ã–∫–∞–º –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        groups = {"ru": [], "en": [], "mixed": [], "unknown": []}
        
        for message in messages:
            language = self._detect_primary_language(message.text or "")
            groups[language].append(message)
        
        # –£–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ –≥—Ä—É–ø–ø—ã
        return {lang: msgs for lang, msgs in groups.items() if msgs}
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        success_rate = (
            self._successful_requests / self._total_requests 
            if self._total_requests > 0 else 0
        )
        
        avg_processing_time = (
            self._total_processing_time / self._successful_requests
            if self._successful_requests > 0 else 0
        )
        
        spam_detection_rate = (
            self._spam_detected / self._successful_requests
            if self._successful_requests > 0 else 0
        )
        
        return {
            "total_requests": self._total_requests,
            "successful_requests": self._successful_requests,
            "failed_requests": self._failed_requests,
            "spam_detected": self._spam_detected,
            "success_rate": success_rate,
            "average_processing_time_ms": avg_processing_time,
            "spam_detection_rate": spam_detection_rate
        }
    
    async def health_check(self) -> Dict[str, Any]:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è OpenAI detector
        
        Returns:
            –°—Ç–∞—Ç—É—Å –∑–¥–æ—Ä–æ–≤—å—è —Å–∏—Å—Ç–µ–º—ã
        """
        try:
            # –í—ã–ø–æ–ª–Ω—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            start_time = time.time()
            
            test_text = "–¢–µ—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ API"
            test_context = {"is_new_user": False}
            
            test_result = await self.openai_gateway.analyze_spam(test_text, test_context)
            
            response_time_ms = (time.time() - start_time) * 1000
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞
            if not isinstance(test_result, dict):
                raise ValueError(f"Invalid response format: {type(test_result)}")
            
            required_fields = ["is_spam", "confidence"]
            missing_fields = [field for field in required_fields if field not in test_result]
            
            if missing_fields:
                raise ValueError(f"Missing required fields: {missing_fields}")
            
            return {
                "status": "healthy",
                "api_available": True,
                "response_time_ms": response_time_ms,
                "test_result": {
                    "is_spam": test_result.get("is_spam"),
                    "confidence": test_result.get("confidence")
                },
                "performance": self.get_performance_stats(),
                "config": {
                    "model": getattr(self.openai_gateway, 'model', 'unknown'),
                    "timeout": self.timeout,
                    "min_text_length": self.min_text_length,
                    "use_user_context": self.use_user_context
                }
            }
            
        except Exception as e:
            logger.error(f"‚ùå OpenAI health check failed: {e}")
            
            return {
                "status": "error",
                "api_available": False,
                "error": str(e),
                "performance": self.get_performance_stats()
            }
    
    async def validate_configuration(self) -> Dict[str, Any]:
        """
        –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é OpenAI detector
        
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        """
        validation_result = {
            "status": "valid",
            "errors": [],
            "warnings": [],
            "recommendations": []
        }
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º gateway
            if not self.openai_gateway:
                validation_result["errors"].append("OpenAI gateway not configured")
                validation_result["status"] = "invalid"
                return validation_result
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º API key
            if not hasattr(self.openai_gateway, 'api_key') or not self.openai_gateway.api_key:
                validation_result["errors"].append("OpenAI API key not configured")
                validation_result["status"] = "invalid"
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª—å
            model = getattr(self.openai_gateway, 'model', None)
            if not model:
                validation_result["warnings"].append("OpenAI model not specified")
            elif model not in ["gpt-4", "gpt-4-turbo", "gpt-4o", "gpt-4o-mini"]:
                validation_result["warnings"].append(f"Unusual OpenAI model: {model}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º timeout settings
            if self.timeout < 1.0:
                validation_result["warnings"].append("Very low timeout - may cause frequent failures")
            elif self.timeout > 10.0:
                validation_result["warnings"].append("High timeout - may impact performance")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º text length limits
            if self.min_text_length < 5:
                validation_result["recommendations"].append("Consider increasing min_text_length for better accuracy")
            
            if self.max_text_length > 8000:
                validation_result["warnings"].append("High max_text_length may increase costs and latency")
            
            # –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            health = await self.health_check()
            if health["status"] != "healthy":
                validation_result["errors"].append(f"Health check failed: {health.get('error')}")
                validation_result["status"] = "invalid"
            
        except Exception as e:
            validation_result["errors"].append(f"Validation failed: {str(e)}")
            validation_result["status"] = "error"
        
        return validation_result
    
    def reset_stats(self):
        """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)"""
        self._total_requests = 0
        self._successful_requests = 0
        self._failed_requests = 0
        self._spam_detected = 0
        self._total_processing_time = 0.0
        logger.info("üìä OpenAI —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–±—Ä–æ—à–µ–Ω–∞")
