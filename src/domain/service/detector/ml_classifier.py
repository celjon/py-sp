import pickle
import asyncio
import re
from pathlib import Path
from typing import Dict, Any, Optional
from dataclasses import dataclass
from sklearn.pipeline import Pipeline
from src.lib.utils.text_processing import TextProcessor

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ BERT –º–æ–¥–µ–ª–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
try:
    import torch
    from transformers import AutoTokenizer, AutoModelForSequenceClassification
    BERT_AVAILABLE = True
except ImportError:
    BERT_AVAILABLE = False
    print("‚ö†Ô∏è PyTorch/Transformers not available. Using sklearn fallback.")

@dataclass
class MLResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç ML –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    is_spam: bool
    confidence: float
    details: str
    model_name: str

class MLClassifier:
    """ML –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å–ø–∞–º–∞"""
    
    def __init__(self, model_path: Path, config: Dict[str, Any]):
        self.model_path = model_path
        self.config = config
        self.model: Optional[Pipeline] = None
        self.vectorizer = None
        self.text_processor = TextProcessor()
        self.spam_threshold = config.get("spam_threshold", 0.6)
        
        # BERT –º–æ–¥–µ–ª—å –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
        self.bert_model = None
        self.bert_tokenizer = None
        self.device = None
        self.use_bert = config.get("use_bert", True) and BERT_AVAILABLE
        self.bert_model_name = config.get("bert_model_name", "RUSpam/spamNS_v1")
        
    async def load_model(self):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
        try:
            # –°–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å BERT –º–æ–¥–µ–ª—å
            if self.use_bert:
                await self._load_bert_model()
            
            # –ó–∞—Ç–µ–º –∑–∞–≥—Ä—É–∂–∞–µ–º fallback sklearn –º–æ–¥–µ–ª—å
            model_file = self.model_path / "spam_classifier.pkl"
            if model_file.exists():
                with open(model_file, 'rb') as f:
                    self.model = pickle.load(f)
                print(f"‚úÖ Sklearn model loaded from {model_file}")
            else:
                print(f"‚ö†Ô∏è Model file not found: {model_file}")
                self.model = self._create_fallback_model()
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ–∫—Ç–æ—Ä–∞–π–∑–µ—Ä –æ—Ç–¥–µ–ª—å–Ω–æ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
            vectorizer_file = self.model_path / "vectorizer.pkl"
            if vectorizer_file.exists():
                with open(vectorizer_file, 'rb') as f:
                    self.vectorizer = pickle.load(f)
                print(f"‚úÖ Vectorizer loaded from {vectorizer_file}")
                
        except Exception as e:
            print(f"‚ùå Error loading ML model: {e}")
            self.model = self._create_fallback_model()

    async def _load_bert_model(self):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å BERT –º–æ–¥–µ–ª—å –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞"""
        try:
            if not BERT_AVAILABLE:
                print("‚ö†Ô∏è BERT dependencies not available")
                self.use_bert = False
                return
                
            print(f"ü§ñ Loading BERT model: {self.bert_model_name}")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            print(f"üì± Using device: {self.device}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º RUSpam –º–æ–¥–µ–ª—å
            try:
                self.bert_tokenizer = AutoTokenizer.from_pretrained(self.bert_model_name)
                # –í —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å —Ç–µ—Å—Ç–æ–º RUSpam/spamNS_v1 ‚Äî —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å –æ–¥–Ω–∏–º –≤—ã—Ö–æ–¥–æ–º
                self.bert_model = AutoModelForSequenceClassification.from_pretrained(
                    self.bert_model_name,
                    num_labels=1,
                    ignore_mismatched_sizes=True
                ).to(self.device).eval()
                print(f"‚úÖ RUSpam –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ (—Ä–µ–≥—Ä–µ—Å—Å–∏—è, 1 –≤—ã—Ö–æ–¥)")
            except Exception as e:
                print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å RUSpam: {e}")
                print("üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ: pip install torch transformers")
                self.use_bert = False
            
        except Exception as e:
            print(f"‚ùå Error loading BERT model: {e}")
            self.use_bert = False
    
    def _create_fallback_model(self) -> Pipeline:
        """–°–æ–∑–¥–∞—Ç—å –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω–∞—è –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞"""
        from sklearn.feature_extraction.text import TfidfVectorizer
        from sklearn.naive_bayes import MultinomialNB
        
        vectorizer = TfidfVectorizer(
            max_features=1000,
            ngram_range=(1, 2),
            stop_words='english'
        )
        
        classifier = MultinomialNB(alpha=1.0)
        
        pipeline = Pipeline([
            ('vectorizer', vectorizer),
            ('classifier', classifier)
        ])
        
        print("‚ö†Ô∏è Using fallback ML model")
        return pipeline
    
    async def classify(self, text: str) -> MLResult:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç"""
        if not self.model and not self.bert_model:
            await self.load_model()
        
        try:
            # –°–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å BERT –º–æ–¥–µ–ª—å
            if self.use_bert and self.bert_model is not None:
                return await self._classify_with_bert(text)
            
            # Fallback –Ω–∞ sklearn –º–æ–¥–µ–ª—å
            return await self._classify_with_sklearn(text)
            
        except Exception as e:
            print(f"ML classification error: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            return MLResult(
                is_spam=False,
                confidence=0.0,
                details=f"ML error: {str(e)}",
                model_name="ML_Classifier_Error"
            )

    async def _classify_with_bert(self, text: str) -> MLResult:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é BERT –º–æ–¥–µ–ª–∏"""
        try:
            # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ –º–µ—Ç–æ–¥—É RUSpam
            cleaned_text = self._clean_text_for_bert(text)
            
            if len(cleaned_text.strip()) < 3:
                return MLResult(
                    is_spam=False,
                    confidence=0.0,
                    details="Text too short for BERT classification",
                    model_name="BERT_RUSpam"
                )
            
            # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
            # –î–ª—è –º–æ–¥–µ–ª–µ–π —Å–µ–º–µ–π—Å—Ç–≤–∞ DeBERTa/Roberta –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å max_length –¥–æ 512,
            # –Ω–æ —É RUSpam/spamNS_v1 –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ 128 –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
            encoding = self.bert_tokenizer(
                cleaned_text,
                padding='max_length',
                truncation=True,
                max_length=128,
                return_tensors='pt'
            )
            
            input_ids = encoding['input_ids'].to(self.device)
            attention_mask = encoding['attention_mask'].to(self.device)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ (–≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å —Ç–µ—Å—Ç–æ–º: —Ä–µ–≥—Ä–µ—Å—Å–∏—è + sigmoid)
            with torch.no_grad():
                outputs = self.bert_model(input_ids, attention_mask=attention_mask).logits
                spam_prob_tensor = torch.sigmoid(outputs)
                spam_prob = float(spam_prob_tensor.cpu().numpy()[0][0])

            is_spam = bool(spam_prob >= 0.5)
            confidence = float(spam_prob)
            
            details = self._generate_details(text, is_spam, confidence)
            details += " (BERT model)"
            
            return MLResult(
                is_spam=is_spam,
                confidence=confidence,
                details=details,
                model_name="BERT_RUSpam"
            )
            
        except Exception as e:
            print(f"BERT classification error: {e}")
            # Fallback –Ω–∞ sklearn
            return await self._classify_with_sklearn(text)

    async def _classify_with_sklearn(self, text: str) -> MLResult:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é sklearn –º–æ–¥–µ–ª–∏"""
        try:
            # –ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç
            cleaned_text = self.text_processor.clean_text(text)
            
            if len(cleaned_text.strip()) < 3:
                return MLResult(
                    is_spam=False,
                    confidence=0.0,
                    details="Text too short for ML classification",
                    model_name="Sklearn_Fallback"
                )
            
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            prediction = self.model.predict([cleaned_text])[0]
            probabilities = self.model.predict_proba([cleaned_text])[0]
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            confidence = probabilities[prediction]
            is_spam = bool(prediction)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–µ—Ç–∞–ª–∏
            details = self._generate_details(text, is_spam, confidence)
            details += " (sklearn model)"
            
            return MLResult(
                is_spam=is_spam,
                confidence=confidence,
                details=details,
                model_name="Sklearn_Classifier"
            )
            
        except Exception as e:
            print(f"Sklearn classification error: {e}")
            return MLResult(
                is_spam=False,
                confidence=0.0,
                details=f"Sklearn error: {str(e)}",
                model_name="Sklearn_Error"
            )

    def _clean_text_for_bert(self, text: str) -> str:
        """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è BERT –º–æ–¥–µ–ª–∏ (–ø–æ –º–µ—Ç–æ–¥—É RUSpam)"""
        # –£–¥–∞–ª—è–µ–º URL
        text = re.sub(r'http\S+', '', text)
        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ä—É—Å—Å–∫–∏–µ –±—É–∫–≤—ã, —Ü–∏—Ñ—Ä—ã –∏ –ø—Ä–æ–±–µ–ª—ã
        text = re.sub(r'[^–ê-–Ø–∞-—è0-9 ]+', ' ', text)
        # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –∏ —É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        text = text.lower().strip()
        text = re.sub(r'\s+', ' ', text)
        return text
    
    def _generate_details(self, text: str, is_spam: bool, confidence: float) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–µ—Ç–∞–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        features = self.text_processor.extract_features(text)
        
        details_parts = []
        
        if features.get('caps_ratio', 0) > 0.7:
            details_parts.append("high caps ratio")
        
        if features.get('emoji_count', 0) > 3:
            details_parts.append("many emojis")
        
        if features.get('url_count', 0) > 2:
            details_parts.append("multiple links")
        
        if features.get('exclamation_count', 0) > 3:
            details_parts.append("many exclamations")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ø–∞–º-–ø–∞—Ç—Ç–µ—Ä–Ω—ã
        spam_patterns = self.text_processor.contains_spam_patterns(text)
        for category, info in spam_patterns.items():
            if info['count'] > 0:
                details_parts.append(f"{category}: {info['found']}")
        
        if not details_parts:
            details_parts.append("text analysis")
        
        details = ", ".join(details_parts)
        
        if is_spam:
            if confidence > 0.8:
                details += " (high confidence)"
            elif confidence > 0.6:
                details += " (medium confidence)"
            else:
                details += " (low confidence)"
        
        return details
    
    async def update_model(self, new_samples: list):
        """–û–±–Ω–æ–≤–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–æ–≤—ã–º–∏ –æ–±—Ä–∞–∑—Ü–∞–º–∏"""
        if not self.model:
            await self.load_model()
        
        try:
            # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ –¥–æ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
            # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º
            await self.load_model()
            print("‚úÖ Model updated successfully")
        except Exception as e:
            print(f"‚ùå Error updating model: {e}")
    
    def get_model_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏"""
        return {
            "model_type": type(self.model).__name__ if self.model else "None",
            "vectorizer_type": type(self.vectorizer).__name__ if self.vectorizer else "None",
            "spam_threshold": self.spam_threshold,
            "model_path": str(self.model_path),
            "is_loaded": self.model is not None
        }
