from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import List, Optional, Dict, Any


class DetectionReason(Enum):
    """ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ñ‹ Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¸ ÑĞ¿Ğ°Ğ¼Ğ° - Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°"""

    CAS_BANNED = "CAS"

    CLASSIFIER = "classifier"
    RUSPAM_DETECTED = "ML"
    RUSPAM_CLEAN = "ruspam_clean"

    BOTHUB_DETECTED = "BotHub"
    BOTHUB_CLEAN = "bothub_clean"

    ADMIN_REPORTED = "admin_reported"


@dataclass
class DetectorResult:
    """Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€Ğ°"""

    detector_name: str
    is_spam: bool
    confidence: float
    details: str
    processing_time_ms: float = 0.0
    error: Optional[str] = None
    token_usage: Optional[Dict[str, int]] = (
        None
    )


@dataclass
class DetectionResult:
    """Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğ¹ Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¸ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ"""

    message_id: Optional[int]
    user_id: int
    is_spam: bool
    overall_confidence: float
    primary_reason: DetectionReason
    detector_results: List[DetectorResult] = field(default_factory=list)

    should_delete: bool = False
    should_ban: bool = False
    should_restrict: bool = False
    should_warn: bool = False

    processing_time_ms: float = 0.0
    created_at: datetime = field(default_factory=datetime.now)
    metadata: Dict[str, Any] = field(default_factory=dict)

    @property
    def spam_detectors(self) -> List[DetectorResult]:
        """Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€Ñ‹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶Ğ¸Ğ»Ğ¸ ÑĞ¿Ğ°Ğ¼"""
        return [dr for dr in self.detector_results if dr.is_spam]

    @property
    def clean_detectors(self) -> List[DetectorResult]:
        """Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€Ñ‹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ½Ğµ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶Ğ¸Ğ»Ğ¸ ÑĞ¿Ğ°Ğ¼"""
        return [dr for dr in self.detector_results if not dr.is_spam]

    @property
    def max_confidence(self) -> float:
        """Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½ÑƒÑ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ ÑÑ€ĞµĞ´Ğ¸ Ğ²ÑĞµÑ… Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€Ğ¾Ğ²"""
        if not self.detector_results:
            return 0.0
        return max(dr.confidence for dr in self.detector_results)

    @property
    def spam_detector_names(self) -> List[str]:
        """Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ¸Ğ¼ĞµĞ½Ğ° Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€Ğ¾Ğ², Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶Ğ¸Ğ²ÑˆĞ¸Ñ… ÑĞ¿Ğ°Ğ¼"""
        return [dr.detector_name for dr in self.spam_detectors]

    def add_detector_result(self, result: DetectorResult):
        """Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµÑ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€Ğ°"""
        self.detector_results.append(result)

        if result.is_spam and result.confidence > self.overall_confidence:
            self.overall_confidence = result.confidence

    def determine_actions(self, spam_threshold: float = 0.6):
        """ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµĞ¼Ñ‹Ğµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²"""
        if not self.is_spam:
            return

        if self.overall_confidence >= 0.9:
            self.should_ban = True
            self.should_delete = True
        elif self.overall_confidence >= spam_threshold:
            self.should_restrict = True
            self.should_delete = True
        else:
            self.should_warn = True
            self.should_delete = self.overall_confidence > 0.5

    def to_summary(self) -> str:
        """Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ ĞºÑ€Ğ°Ñ‚ĞºĞ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°"""
        if not self.is_spam:
            return f"âœ… Clean message (confidence: {self.overall_confidence:.2f})"

        action = (
            "ğŸ”¨ Ban" if self.should_ban else "ğŸ”‡ Restrict" if self.should_restrict else "âš ï¸ Warn"
        )
        detectors = ", ".join(self.spam_detector_names)

        return (
            f"ğŸš¨ Spam detected: {action}\n"
            f"ğŸ“Š Confidence: {self.overall_confidence:.2f}\n"
            f"ğŸ” Detectors: {detectors}\n"
            f"âš¡ Time: {self.processing_time_ms:.1f}ms"
        )
