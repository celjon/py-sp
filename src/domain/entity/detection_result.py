from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import List, Optional, Dict, Any


class DetectionReason(Enum):
    """ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ñ‹ Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¸ ÑĞ¿Ğ°Ğ¼Ğ°"""
    SIMILARITY = "similarity"  # ĞŸĞ¾Ñ…Ğ¾Ğ¶ĞµÑÑ‚ÑŒ Ğ½Ğ° Ğ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğ¹ ÑĞ¿Ğ°Ğ¼
    CLASSIFIER = "classifier"  # ML ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€
    CAS_BANNED = "cas_banned"  # Ğ—Ğ°Ğ±Ğ°Ğ½ĞµĞ½ Ğ² CAS
    STOP_WORDS = "stop_words"  # Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ ÑÑ‚Ğ¾Ğ¿-ÑĞ»Ğ¾Ğ²Ğ°
    TOO_MANY_EMOJI = "too_many_emoji"  # Ğ¡Ğ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ ÑĞ¼Ğ¾Ğ´Ğ¶Ğ¸
    TOO_MANY_LINKS = "too_many_links"  # Ğ¡Ğ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ ÑÑÑ‹Ğ»Ğ¾Ğº
    TOO_MANY_MENTIONS = "too_many_mentions"  # Ğ¡Ğ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ ÑƒĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ğ½Ğ¸Ğ¹
    LINKS_ONLY = "links_only"  # Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ ÑÑÑ‹Ğ»ĞºĞ¸
    IMAGES_ONLY = "images_only"  # Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ
    FORWARD_SPAM = "forward_spam"  # Ğ¤Ğ¾Ñ€Ğ²Ğ°Ñ€Ğ´ ÑĞ¿Ğ°Ğ¼Ğ°
    MULTI_LANGUAGE = "multi_language"  # ĞœÑƒĞ»ÑŒÑ‚Ğ¸ÑĞ·Ñ‹Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ
    OPENAI_DETECTED = "openai_detected"  # ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ OpenAI
    ADMIN_REPORTED = "admin_reported"  # ĞŸĞ¾Ğ¼ĞµÑ‡ĞµĞ½Ğ¾ Ğ°Ğ´Ğ¼Ğ¸Ğ½Ğ¾Ğ¼
    DUPLICATE_MESSAGE = "duplicate_message"  # Ğ”ÑƒĞ±Ğ»Ğ¸Ñ€ÑƒÑÑ‰ĞµĞµÑÑ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ
    ABNORMAL_SPACING = "abnormal_spacing"  # ĞĞ½Ğ¾Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ñ‹
    USERNAME_SYMBOLS = "username_symbols"  # Ğ—Ğ°Ğ¿Ñ€ĞµÑ‰ĞµĞ½Ğ½Ñ‹Ğµ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ñ‹ Ğ² Ğ¸Ğ¼ĞµĞ½Ğ¸
    PLUGIN_DETECTED = "plugin_detected"  # ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ Ğ¿Ğ»Ğ°Ğ³Ğ¸Ğ½Ğ¾Ğ¼


@dataclass
class DetectorResult:
    """Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€Ğ°"""
    detector_name: str
    is_spam: bool
    confidence: float
    details: str
    processing_time_ms: float = 0.0
    error: Optional[str] = None


@dataclass 
class DetectionResult:
    """Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğ¹ Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¸ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ"""
    message_id: Optional[int]
    user_id: int
    is_spam: bool
    overall_confidence: float
    primary_reason: DetectionReason
    detector_results: List[DetectorResult] = field(default_factory=list)
    
    # Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµĞ¼Ñ‹Ğµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ
    should_delete: bool = False
    should_ban: bool = False
    should_restrict: bool = False
    should_warn: bool = False
    
    # Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ
    processing_time_ms: float = 0.0
    created_at: datetime = field(default_factory=datetime.now)
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    @property
    def spam_detectors(self) -> List[DetectorResult]:
        """Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€Ñ‹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶Ğ¸Ğ»Ğ¸ ÑĞ¿Ğ°Ğ¼"""
        return [dr for dr in self.detector_results if dr.is_spam]
    
    @property
    def clean_detectors(self) -> List[DetectorResult]:
        """Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€Ñ‹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ½Ğµ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶Ğ¸Ğ»Ğ¸ ÑĞ¿Ğ°Ğ¼"""
        return [dr for dr in self.detector_results if not dr.is_spam]
    
    @property
    def max_confidence(self) -> float:
        """Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½ÑƒÑ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ ÑÑ€ĞµĞ´Ğ¸ Ğ²ÑĞµÑ… Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€Ğ¾Ğ²"""
        if not self.detector_results:
            return 0.0
        return max(dr.confidence for dr in self.detector_results)
    
    @property
    def spam_detector_names(self) -> List[str]:
        """Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ¸Ğ¼ĞµĞ½Ğ° Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€Ğ¾Ğ², Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶Ğ¸Ğ²ÑˆĞ¸Ñ… ÑĞ¿Ğ°Ğ¼"""
        return [dr.detector_name for dr in self.spam_detectors]
    
    def add_detector_result(self, result: DetectorResult):
        """Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµÑ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€Ğ°"""
        self.detector_results.append(result)
        
        # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ¾Ğ±Ñ‰ÑƒÑ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ (Ğ²Ğ·Ğ²ĞµÑˆĞµĞ½Ğ½Ğ¾Ğµ ÑÑ€ĞµĞ´Ğ½ĞµĞµ)
        if result.is_spam and result.confidence > self.overall_confidence:
            self.overall_confidence = result.confidence
    
    def determine_actions(self, spam_threshold: float = 0.6):
        """ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµĞ¼Ñ‹Ğµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²"""
        if not self.is_spam:
            return
        
        # Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ - Ğ±Ğ°Ğ½
        if self.overall_confidence >= 0.9:
            self.should_ban = True
            self.should_delete = True
        # Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ - Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ
        elif self.overall_confidence >= spam_threshold:
            self.should_restrict = True
            self.should_delete = True
        # ĞĞ¸Ğ·ĞºĞ°Ñ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ - Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ğµ
        else:
            self.should_warn = True
            self.should_delete = True
    
    def to_summary(self) -> str:
        """Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ ĞºÑ€Ğ°Ñ‚ĞºĞ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°"""
        if not self.is_spam:
            return f"âœ… Clean message (confidence: {self.overall_confidence:.2f})"
        
        action = "ğŸ”¨ Ban" if self.should_ban else "ğŸ”‡ Restrict" if self.should_restrict else "âš ï¸ Warn"
        detectors = ", ".join(self.spam_detector_names)
        
        return (
            f"ğŸš¨ Spam detected: {action}\n"
            f"ğŸ“Š Confidence: {self.overall_confidence:.2f}\n"
            f"ğŸ” Detectors: {detectors}\n"
            f"âš¡ Time: {self.processing_time_ms:.1f}ms"
        )

