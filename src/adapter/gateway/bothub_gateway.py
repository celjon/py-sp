# src/adapter/gateway/bothub_gateway.py
"""
BotHub Gateway - OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è BotHub API
"""

import asyncio
import json
import logging
import time
from typing import Dict, Any, Optional, Tuple, List
import httpx
from openai import AsyncOpenAI

logger = logging.getLogger(__name__)


class BotHubGateway:
    """
    BotHub Gateway - OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å–ø–∞–º–∞
    
    Features:
    - OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π API —á–µ—Ä–µ–∑ BotHub
    - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤
    - –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
    - Comprehensive error handling
    - Health checks –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
    """

    def __init__(self, user_token: str, system_prompt: str = None, config: Dict[str, Any] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è BotHub Gateway
        
        Args:
            user_token: –¢–æ–∫–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è BotHub
            system_prompt: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏
            config: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        """
        self.user_token = user_token
        self.system_prompt = system_prompt or self._get_default_prompt()
        self.config = config or {}
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        self.model = self.config.get("model", "gpt-4o-mini")
        self.max_tokens = self.config.get("max_tokens", 150)
        self.temperature = self.config.get("temperature", 0.0)
        self.timeout = self.config.get("timeout", 10.0)
        self.max_retries = self.config.get("max_retries", 2)
        self.retry_delay = self.config.get("retry_delay", 1.0)
        
        # BotHub API –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        self.base_url = "https://bothub.chat/api/v2/openai/v1"
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI –∫–ª–∏–µ–Ω—Ç–∞
        self.client = AsyncOpenAI(
            api_key=self.user_token,
            base_url=self.base_url,
            timeout=self.timeout
        )
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self._total_requests = 0
        self._total_processing_time = 0.0
        self._last_health_check = 0
        self._last_health_status = {"status": "unknown"}
        
        logger.info(f"üîó BotHub Gateway –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        logger.info(f"   –ú–æ–¥–µ–ª—å: {self.model}")
        logger.info(f"   Max tokens: {self.max_tokens}")
        logger.info(f"   Timeout: {self.timeout}s")

    async def check_spam(
        self, text: str, user_context: Optional[Dict] = None
    ) -> Tuple[bool, float, Dict[str, int]]:
        """
        –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ —á–µ—Ä–µ–∑ BotHub API
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            user_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            
        Returns:
            (is_spam, confidence, token_usage)
        """
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            context_info = ""
            if user_context:
                context_info = f"""
User context:
- Message count: {user_context.get('message_count', 0)}
- Spam score: {user_context.get('spam_score', 0.0)}
- Is new user: {user_context.get('is_new_user', False)}
"""

            # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å
            messages = [
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": f"{context_info}\n\nMessage to analyze: {text}"},
            ]

            # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ BotHub
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=self.max_tokens,
                temperature=self.temperature,
                response_format={"type": "json_object"}
            )

            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
            content = response.choices[0].message.content
            result = json.loads(content)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            is_spam = result.get("is_spam", False)
            confidence = float(result.get("confidence", 0.0))
            
            # –¢–æ–∫–µ–Ω—ã
            token_usage = {
                "prompt_tokens": response.usage.prompt_tokens,
                "completion_tokens": response.usage.completion_tokens,
                "total_tokens": response.usage.total_tokens
            }
            
            self._total_requests += 1
            
            logger.debug(f"üîó BotHub –∞–Ω–∞–ª–∏–∑: is_spam={is_spam}, confidence={confidence:.3f}")
            
            return is_spam, confidence, token_usage
            
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå BotHub JSON decode error: {e}")
            return False, 0.0, {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}
            
        except Exception as e:
            logger.error(f"‚ùå BotHub API error: {e}")
            return False, 0.0, {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}

    async def health_check(self) -> Dict[str, Any]:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è BotHub API
        
        Returns:
            –°—Ç–∞—Ç—É—Å API
        """
        current_time = time.time()
        
        # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ 30 —Å–µ–∫—É–Ω–¥
        if current_time - self._last_health_check < 30:
            return self._last_health_status
            
        try:
            # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            test_messages = [
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": "Hello"}
            ]
            
            start_time = time.time()
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=test_messages,
                max_tokens=10,
                temperature=0.0
            )
            
            response_time = (time.time() - start_time) * 1000
            
            self._last_health_status = {
                "status": "healthy",
                "response_time_ms": response_time,
                "model": self.model,
                "last_check": current_time,
                "total_requests": self._total_requests,
                "avg_processing_time": self._total_processing_time / max(self._total_requests, 1)
            }
            
            self._last_health_check = current_time
            
        except Exception as e:
            self._last_health_status = {
                "status": "error",
                "error": str(e),
                "last_check": current_time
            }
            self._last_health_check = current_time

        return self._last_health_status

    def update_system_prompt(self, new_prompt: str) -> None:
        """
        –û–±–Ω–æ–≤–∏—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        
        Args:
            new_prompt: –ù–æ–≤—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        """
        self.system_prompt = new_prompt
        logger.info("üîó BotHub —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –æ–±–Ω–æ–≤–ª–µ–Ω")

    def update_user_token(self, new_token: str) -> None:
        """
        –û–±–Ω–æ–≤–∏—Ç—å —Ç–æ–∫–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        
        Args:
            new_token: –ù–æ–≤—ã–π —Ç–æ–∫–µ–Ω
        """
        self.user_token = new_token
        self.client = AsyncOpenAI(
            api_key=self.user_token,
            base_url=self.base_url,
            timeout=self.timeout
        )
        logger.info("üîó BotHub —Ç–æ–∫–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω")

    def _get_default_prompt(self) -> str:
        """–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å–ø–∞–º–∞"""
        return """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é —Å–ø–∞–º–∞ –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö —á–∞—Ç–æ–≤. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –±—ã—Å—Ç—Ä–æ –∏ —Ç–æ—á–Ω–æ.

–ó–ê–î–ê–ß–ê: –û–ø—Ä–µ–¥–µ–ª–∏, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–ø–∞–º–æ–º.

–°–ü–ê–ú —ç—Ç–æ:
- –†–µ–∫–ª–∞–º–∞ —Ç–æ–≤–∞—Ä–æ–≤/—É—Å–ª—É–≥ –±–µ–∑ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è
- –ü—Ä–∏–∑—ã–≤—ã –ø–∏—Å–∞—Ç—å –≤ –ª–∏—á–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è "–∑–∞—Ä–∞–±–æ—Ç–∫–∞"
- –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Å—Ö–µ–º—ã –∏ "–±—ã—Å—Ç—Ä—ã–µ –¥–µ–Ω—å–≥–∏"
- –ú–∞—Å—Å–æ–≤—ã–µ —Ä–∞—Å—Å—ã–ª–∫–∏ –∏ –∫–æ–ø–∏–ø–∞—Å—Ç–∞
- –ù–∞–≤—è–∑—á–∏–≤—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –≤–Ω–µ—à–Ω–∏–µ —Ä–µ—Å—É—Ä—Å—ã
- –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π, –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç, —Ñ–æ—Ä–µ–∫—Å–∞

–ù–ï –°–ü–ê–ú —ç—Ç–æ:
- –û–±—ã—á–Ω–æ–µ –æ–±—â–µ–Ω–∏–µ –∏ –≤–æ–ø—Ä–æ—Å—ã
- –û–±–º–µ–Ω –æ–ø—ã—Ç–æ–º –ø–æ —Ç–µ–º–µ —á–∞—Ç–∞
- –ú–µ–º—ã, —à—É—Ç–∫–∏, —Ä–µ–∞–∫—Ü–∏–∏
- –ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω–∞—è –∫—Ä–∏—Ç–∏–∫–∞
- –ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ —Å—Å—ã–ª–∫–∏ –ø–æ —Ç–µ–º–µ

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (—Ç–æ–ª—å–∫–æ JSON):
{
  "is_spam": boolean,
  "confidence": float (0.0-1.0),
  "reason": "–∫—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º"
}

–ë—É–¥—å –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–º - –ø—Ä–∏ —Å–æ–º–Ω–µ–Ω–∏—è—Ö –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–π –∫–∞–∫ –ù–ï —Å–ø–∞–º."""

    def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        return {
            "total_requests": self._total_requests,
            "total_processing_time": self._total_processing_time,
            "avg_processing_time": self._total_processing_time / max(self._total_requests, 1),
            "model": self.model,
            "base_url": self.base_url
        }

    def get_model_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏"""
        return {
            "model": self.model,
            "max_tokens": self.max_tokens,
            "temperature": self.temperature,
            "timeout": self.timeout,
            "base_url": self.base_url
        }
