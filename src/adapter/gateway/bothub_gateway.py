# src/adapter/gateway/bothub_gateway.py
"""
BotHub Gateway - OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è BotHub API
"""

import asyncio
import json
import logging
import time
from typing import Dict, Any, Optional, Tuple, List
import httpx
from openai import AsyncOpenAI

from src.domain.service.prompt_factory import PromptFactory

logger = logging.getLogger(__name__)


class BotHubGateway:
    """
    BotHub Gateway - OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å–ø–∞–º–∞

    Features:
    - OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π API —á–µ—Ä–µ–∑ BotHub
    - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤
    - –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
    - Comprehensive error handling
    - Health checks –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
    """

    @staticmethod
    async def get_available_models(token: str) -> list[dict]:
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(
                    'https://bothub.chat/api/v2/model/list?children=1',
                    headers={
                        'Authorization': f'Bearer {token}',
                        'Content-Type': 'application/json'
                    },
                    timeout=10.0
                )
                if response.status_code == 200:
                    models = response.json()
                    text_models = [
                        model for model in models
                        if 'TEXT_TO_TEXT' in model.get('features', [])
                    ]
                    return text_models
                return []
        except Exception as e:
            logger.error(f"Error fetching models: {e}")
            return []

    @staticmethod
    async def verify_token(token: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å —Ç–æ–∫–µ–Ω–∞ BotHub

        Args:
            token: –¢–æ–∫–µ–Ω –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏

        Returns:
            bool: True –µ—Å–ª–∏ —Ç–æ–∫–µ–Ω –≤–∞–ª–∏–¥–µ–Ω, False –∏–Ω–∞—á–µ
        """
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    'https://bothub.chat/api/v2/openai/v1/chat/completions',
                    headers={
                        'Authorization': f'Bearer {token}',
                        'Content-Type': 'application/json'
                    },
                    json={
                        'model': 'gpt-4o-mini',
                        'messages': [{'role': 'user', 'content': 'test'}],
                        'max_tokens': 5
                    },
                    timeout=10.0
                )
                return response.status_code in [200, 429]  # 429 = rate limit, –Ω–æ —Ç–æ–∫–µ–Ω –≤–∞–ª–∏–¥–µ–Ω
        except Exception as e:
            logger.error(f"Error verifying token: {e}")
            return False

    def __init__(self, user_token: str, user_instructions: str = None, user_model: str = None, config: Dict[str, Any] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è BotHub Gateway

        Args:
            user_token: –¢–æ–∫–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è BotHub
            user_instructions: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ (–±–µ–∑ —Ñ–æ—Ä–º–∞—Ç–∞ –æ—Ç–≤–µ—Ç–∞)
            user_model: –ú–æ–¥–µ–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏
            config: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        """
        self.user_token = user_token
        self.user_instructions = user_instructions or PromptFactory.get_default_user_instructions()
        self.system_prompt = PromptFactory.build_spam_detection_prompt(self.user_instructions)
        self.config = config or {}

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        self.model = user_model or self.config.get("model", "gpt-4o-mini")
        self.max_tokens = self.config.get("max_tokens", 150)
        self.temperature = self.config.get("temperature", 0.0)
        self.timeout = self.config.get("timeout", 10.0)
        self.max_retries = self.config.get("max_retries", 2)
        self.retry_delay = self.config.get("retry_delay", 1.0)
        
        # BotHub API –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        self.base_url = "https://bothub.chat/api/v2/openai/v1"
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI –∫–ª–∏–µ–Ω—Ç–∞
        self.client = AsyncOpenAI(
            api_key=self.user_token,
            base_url=self.base_url,
            timeout=self.timeout
        )
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self._total_requests = 0
        self._total_processing_time = 0.0
        self._last_health_check = 0
        self._last_health_status = {"status": "unknown"}
        
        logger.info(f"üîó BotHub Gateway –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        logger.info(f"   –ú–æ–¥–µ–ª—å: {self.model}")
        logger.info(f"   Max tokens: {self.max_tokens}")
        logger.info(f"   Timeout: {self.timeout}s")

    async def check_spam(
        self, text: str, user_context: Optional[Dict] = None
    ) -> Tuple[bool, float, Dict[str, int]]:
        """
        –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ —á–µ—Ä–µ–∑ BotHub API
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            user_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            
        Returns:
            (is_spam, confidence, token_usage)
        """
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            context_info = ""
            if user_context:
                context_info = f"""
User context:
- Message count: {user_context.get('message_count', 0)}
- Spam score: {user_context.get('spam_score', 0.0)}
- Is new user: {user_context.get('is_new_user', False)}
"""

            # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å
            messages = [
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": f"{context_info}\n\nMessage to analyze: {text}"},
            ]

            # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ BotHub
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=self.max_tokens,
                temperature=self.temperature,
                response_format={"type": "json_object"}
            )

            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
            content = response.choices[0].message.content
            result = json.loads(content)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            is_spam = result.get("is_spam", False)
            confidence = float(result.get("confidence", 0.0))
            
            # –¢–æ–∫–µ–Ω—ã
            token_usage = {
                "prompt_tokens": response.usage.prompt_tokens,
                "completion_tokens": response.usage.completion_tokens,
                "total_tokens": response.usage.total_tokens
            }
            
            self._total_requests += 1
            
            logger.debug(f"üîó BotHub –∞–Ω–∞–ª–∏–∑: is_spam={is_spam}, confidence={confidence:.3f}")
            
            return is_spam, confidence, token_usage
            
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå BotHub JSON decode error: {e}")
            return False, 0.0, {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}
            
        except Exception as e:
            logger.error(f"‚ùå BotHub API error: {e}")
            return False, 0.0, {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}

    async def health_check(self) -> Dict[str, Any]:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è BotHub API
        
        Returns:
            –°—Ç–∞—Ç—É—Å API
        """
        current_time = time.time()
        
        # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ 30 —Å–µ–∫—É–Ω–¥
        if current_time - self._last_health_check < 30:
            return self._last_health_status
            
        try:
            # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            test_messages = [
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": "Hello"}
            ]
            
            start_time = time.time()
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=test_messages,
                max_tokens=10,
                temperature=0.0
            )
            
            response_time = (time.time() - start_time) * 1000
            
            self._last_health_status = {
                "status": "healthy",
                "response_time_ms": response_time,
                "model": self.model,
                "last_check": current_time,
                "total_requests": self._total_requests,
                "avg_processing_time": self._total_processing_time / max(self._total_requests, 1)
            }
            
            self._last_health_check = current_time
            
        except Exception as e:
            self._last_health_status = {
                "status": "error",
                "error": str(e),
                "last_check": current_time
            }
            self._last_health_check = current_time

        return self._last_health_status

    def update_user_instructions(self, new_instructions: str) -> None:
        """
        –û–±–Ω–æ–≤–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏

        Args:
            new_instructions: –ù–æ–≤—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
        """
        self.user_instructions = new_instructions
        self.system_prompt = PromptFactory.build_spam_detection_prompt(self.user_instructions)
        logger.info("üîó BotHub –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –æ–±–Ω–æ–≤–ª–µ–Ω—ã")

    def update_user_token(self, new_token: str) -> None:
        """
        –û–±–Ω–æ–≤–∏—Ç—å —Ç–æ–∫–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        
        Args:
            new_token: –ù–æ–≤—ã–π —Ç–æ–∫–µ–Ω
        """
        self.user_token = new_token
        self.client = AsyncOpenAI(
            api_key=self.user_token,
            base_url=self.base_url,
            timeout=self.timeout
        )
        logger.info("üîó BotHub —Ç–æ–∫–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω")


    def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        return {
            "total_requests": self._total_requests,
            "total_processing_time": self._total_processing_time,
            "avg_processing_time": self._total_processing_time / max(self._total_requests, 1),
            "model": self.model,
            "base_url": self.base_url
        }

    def get_model_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏"""
        return {
            "model": self.model,
            "max_tokens": self.max_tokens,
            "temperature": self.temperature,
            "timeout": self.timeout,
            "base_url": self.base_url
        }


