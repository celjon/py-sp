"""
BotHub Gateway - OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è BotHub API
"""

import asyncio
import json
import logging
import time
from typing import Dict, Any, Optional, Tuple, List
import httpx
from openai import AsyncOpenAI

from src.domain.service.prompt_factory import PromptFactory

logger = logging.getLogger(__name__)


class BotHubGateway:
    """
    BotHub Gateway - OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å–ø–∞–º–∞

    Features:
    - OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π API —á–µ—Ä–µ–∑ BotHub
    - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤
    - –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
    - Comprehensive error handling
    - Health checks –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
    """

    @staticmethod
    async def get_available_models(token: str) -> list[dict]:
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(
                    'https://bothub.chat/api/v2/model/list?children=1',
                    headers={
                        'Authorization': f'Bearer {token}',
                        'Content-Type': 'application/json'
                    },
                    timeout=60.0
                )
                if response.status_code == 200:
                    models = response.json()
                    text_models = [
                        model for model in models
                        if 'TEXT_TO_TEXT' in model.get('features', [])
                    ]
                    return text_models
                return []
        except Exception as e:
            logger.error(f"Error fetching models: {e}")
            return []

    @staticmethod
    async def verify_token(token: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å —Ç–æ–∫–µ–Ω–∞ BotHub

        Args:
            token: –¢–æ–∫–µ–Ω –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏

        Returns:
            bool: True –µ—Å–ª–∏ —Ç–æ–∫–µ–Ω –≤–∞–ª–∏–¥–µ–Ω, False –∏–Ω–∞—á–µ
        """
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    'https://bothub.chat/api/v2/openai/v1/chat/completions',
                    headers={
                        'Authorization': f'Bearer {token}',
                        'Content-Type': 'application/json'
                    },
                    json={
                        'model': 'gpt-5-nano',
                        'messages': [{'role': 'user', 'content': 'test'}],
                        'max_tokens': 5
                    },
                    timeout=60.0
                )
                return response.status_code in [200, 429]
        except Exception as e:
            logger.error(f"Error verifying token: {e}")
            return False

    def __init__(self, user_token: str, user_instructions: str = None, user_model: str = None, config: Dict[str, Any] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è BotHub Gateway

        Args:
            user_token: –¢–æ–∫–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è BotHub
            user_instructions: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ (–±–µ–∑ —Ñ–æ—Ä–º–∞—Ç–∞ –æ—Ç–≤–µ—Ç–∞)
            user_model: –ú–æ–¥–µ–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏
            config: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        """
        self.user_token = user_token
        self.user_instructions = user_instructions or PromptFactory.get_default_user_instructions()
        self.system_prompt = PromptFactory.build_spam_detection_prompt(self.user_instructions)
        self.config = config or {}

        self.model = user_model or self.config.get("model", "gpt-5-nano")
        self.max_tokens = self.config.get("max_tokens", 1000)
        self.temperature = self.config.get("temperature", 0.0)
        self.timeout = self.config.get("timeout", 60.0)
        self.max_retries = self.config.get("max_retries", 2)
        self.retry_delay = self.config.get("retry_delay", 1.0)
        
        self.base_url = "https://bothub.chat/api/v2/openai/v1"
        
        self.client = AsyncOpenAI(
            api_key=self.user_token,
            base_url=self.base_url,
            timeout=self.timeout
        )
        
        self._total_requests = 0
        self._total_processing_time = 0.0
        self._last_health_check = 0
        self._last_health_status = {"status": "unknown"}
        
        logger.info(f"üîó BotHub Gateway –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        logger.info(f"   –ú–æ–¥–µ–ª—å: {self.model}")
        logger.info(f"   Max tokens: {self.max_tokens}")
        logger.info(f"   Timeout: {self.timeout}s")

    async def check_spam(
        self, text: str, user_context: Optional[Dict] = None
    ) -> Tuple[bool, float, Dict[str, int]]:
        """
        –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ —á–µ—Ä–µ–∑ BotHub API

        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            user_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Returns:
            (is_spam, confidence, token_usage)
        """
        start_time = time.time()

        try:
            context_info = ""
            if user_context:
                context_info = f"""
User context:
- Message count: {user_context.get('message_count', 0)}
- Spam score: {user_context.get('spam_score', 0.0)}
- Is new user: {user_context.get('is_new_user', False)}
"""

            messages = [
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": f"{context_info}\n\nMessage to analyze: {text}"},
            ]

            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
            request_params = {
                "model": self.model,
                "messages": messages,
                "max_tokens": self.max_tokens,
                "temperature": self.temperature
            }

            # –î–ª—è GPT –º–æ–¥–µ–ª–µ–π –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Ç–∫–ª—é—á–∞–µ–º reasoning - –æ—Ç–≤–µ—Ç –±—É–¥–µ—Ç —Ç–æ–ª—å–∫–æ –≤ content
            if self.model.lower().startswith('gpt') or 'gpt' in self.model.lower():
                request_params["reasoning"] = {"max_tokens": 0}  # –ü–æ–ª–Ω–æ–µ –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ reasoning
                logger.debug(f"[BOTHUB] –ü–æ–ª–Ω–æ—Å—Ç—å—é –æ—Ç–∫–ª—é—á–∞–µ–º reasoning –¥–ª—è GPT –º–æ–¥–µ–ª–∏: {self.model}")

            # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Ç—Ä–µ–±—É–µ–º JSON –æ—Ç–≤–µ—Ç –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
            if "max_tokens" in request_params:
                request_params["max_tokens"] = min(request_params["max_tokens"], 200)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏

            response = await self.client.chat.completions.create(**request_params)

            content = response.choices[0].message.content
            logger.info(f"[BOTHUB] Raw API response: {repr(content)}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø—É—Å—Ç–æ–π content
            if not content or content.strip() == "":
                logger.error(f"[BOTHUB] Empty response despite completion_tokens={response.usage.completion_tokens if response.usage else 0}")
                logger.error(f"[BOTHUB] Full response: {response}")
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º "–Ω–µ —Å–ø–∞–º" —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é –ø—Ä–∏ –ø—É—Å—Ç–æ–º –æ—Ç–≤–µ—Ç–µ
                return False, 0.0, {
                    "prompt_tokens": response.usage.prompt_tokens if response.usage else 0,
                    "completion_tokens": response.usage.completion_tokens if response.usage else 0,
                    "total_tokens": response.usage.total_tokens if response.usage else 0
                }

            try:
                # –û—á–∏—â–∞–µ–º content –æ—Ç –≤–æ–∑–º–æ–∂–Ω–æ–≥–æ –º—É—Å–æ—Ä–∞ (–ø—Ä–æ–±–µ–ª—ã, –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫)
                clean_content = content.strip()

                # –ï—Å–ª–∏ –µ—Å—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–æ/–ø–æ—Å–ª–µ JSON, –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —Ç–æ–ª—å–∫–æ JSON
                import re
                json_match = re.search(r'\{[^}]*"is_spam"[^}]*"confidence"[^}]*\}', clean_content)
                if json_match:
                    clean_content = json_match.group(0)
                    logger.debug(f"[BOTHUB] –ò–∑–≤–ª–µ—á–µ–Ω —á–∏—Å—Ç—ã–π JSON: {clean_content}")

                result = json.loads(clean_content)
                logger.info(f"[BOTHUB] Parsed JSON: {result}")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ JSON —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
                if "is_spam" not in result or "confidence" not in result:
                    raise ValueError(f"Missing required fields in response: {result}")

            except (json.JSONDecodeError, ValueError) as e:
                logger.error(f"[BOTHUB] JSON decode/validation error: {e}")
                logger.error(f"[BOTHUB] Full response content (len={len(content)}): {content}")
                logger.error(f"[BOTHUB] Usage: {response.usage}")
                # Fallback - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                return False, 0.0, {
                    "prompt_tokens": response.usage.prompt_tokens if response.usage else 0,
                    "completion_tokens": response.usage.completion_tokens if response.usage else 0,
                    "total_tokens": response.usage.total_tokens if response.usage else 0
                }

            is_spam = result.get("is_spam", False)
            raw_confidence = float(result.get("confidence", 0.0))

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º BotHub confidence –≤ RUSpam-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Ñ–æ—Ä–º–∞—Ç:
            # BotHub: is_spam=true, confidence=0.95 ‚Üí RUSpam: 0.95 (—Å–ø–∞–º)
            # BotHub: is_spam=false, confidence=0.95 ‚Üí RUSpam: 0.05 (–Ω–µ —Å–ø–∞–º)
            confidence = raw_confidence if is_spam else (1.0 - raw_confidence)

            token_usage = {
                "prompt_tokens": response.usage.prompt_tokens,
                "completion_tokens": response.usage.completion_tokens,
                "total_tokens": response.usage.total_tokens,
                "raw_confidence": raw_confidence  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            }

            processing_time = time.time() - start_time
            self._total_requests += 1
            self._total_processing_time += processing_time

            logger.debug(f"üîó BotHub –∞–Ω–∞–ª–∏–∑: is_spam={is_spam}, raw_confidence={raw_confidence:.3f}, normalized_confidence={confidence:.3f}, –≤—Ä–µ–º—è={processing_time*1000:.1f}ms")

            return is_spam, confidence, token_usage
            
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå BotHub JSON decode error: {e}")
            return False, 0.0, {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}
            
        except Exception as e:
            logger.error(f"‚ùå BotHub API error: {e}")
            return False, 0.0, {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}

    async def health_check(self) -> Dict[str, Any]:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è BotHub API —á–µ—Ä–µ–∑ –ø—Ä–æ–≤–µ—Ä–∫—É –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏

        Returns:
            –°—Ç–∞—Ç—É—Å API
        """
        current_time = time.time()

        if current_time - self._last_health_check < 30:
            return self._last_health_status

        try:
            start_time = time.time()

            async with httpx.AsyncClient() as client:
                response = await client.get(
                    'https://bothub.chat/api/v2/model/list?children=1',
                    headers={
                        'Authorization': f'Bearer {self.user_token}',
                        'Content-Type': 'application/json'
                    },
                    timeout=60.0
                )

                response_time = (time.time() - start_time) * 1000

                if response.status_code == 200:
                    models = response.json()
                    model_found = any(
                        model.get('id') == self.model or model.get('label') == self.model
                        for model in models
                    )

                    status = "healthy" if model_found else "warning"

                    self._last_health_status = {
                        "status": status,
                        "response_time_ms": response_time,
                        "model": self.model,
                        "model_available": model_found,
                        "last_check": current_time,
                        "total_requests": self._total_requests,
                        "avg_processing_time": self._total_processing_time / max(self._total_requests, 1)
                    }
                else:
                    self._last_health_status = {
                        "status": "error",
                        "error": f"HTTP {response.status_code}",
                        "model": self.model,
                        "last_check": current_time
                    }

            self._last_health_check = current_time

        except Exception as e:
            logger.warning(f"BotHub health check failed: {e}")
            self._last_health_status = {
                "status": "error",
                "error": str(e),
                "model": self.model,
                "last_check": current_time
            }
            self._last_health_check = current_time

        return self._last_health_status

    def update_user_instructions(self, new_instructions: str) -> None:
        """
        –û–±–Ω–æ–≤–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏

        Args:
            new_instructions: –ù–æ–≤—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
        """
        self.user_instructions = new_instructions
        self.system_prompt = PromptFactory.build_spam_detection_prompt(self.user_instructions)
        logger.info("üîó BotHub –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –æ–±–Ω–æ–≤–ª–µ–Ω—ã")

    def update_user_token(self, new_token: str) -> None:
        """
        –û–±–Ω–æ–≤–∏—Ç—å —Ç–æ–∫–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        
        Args:
            new_token: –ù–æ–≤—ã–π —Ç–æ–∫–µ–Ω
        """
        self.user_token = new_token
        self.client = AsyncOpenAI(
            api_key=self.user_token,
            base_url=self.base_url,
            timeout=self.timeout
        )
        logger.info("üîó BotHub —Ç–æ–∫–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω")


    def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        return {
            "total_requests": self._total_requests,
            "total_processing_time": self._total_processing_time,
            "avg_processing_time": self._total_processing_time / max(self._total_requests, 1),
            "model": self.model,
            "base_url": self.base_url
        }

    def get_model_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏"""
        return {
            "model": self.model,
            "max_tokens": self.max_tokens,
            "temperature": self.temperature,
            "timeout": self.timeout,
            "base_url": self.base_url
        }


